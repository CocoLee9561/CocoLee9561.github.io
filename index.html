<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Vinci&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Vinci&#39;s blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Vinci&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Vinci Xu">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Vinci's blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Vinci&#39;s blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">This is Vinci</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-prometheus/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/prometheus/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.216Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/prometheus/README/">Prometheus</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h1><h2 id="Prometheus远程存储优化"><a href="#Prometheus远程存储优化" class="headerlink" title="Prometheus远程存储优化"></a>Prometheus远程存储优化</h2><p>Prometheus 以每两个小时为一个块，存储到磁盘中，内存保存近两个小时的内容，同时也会写 <code>WAL(write-ahead-log)</code>，预写日志文件wal以128MB的段存储在目录中。这些文件包含尚未压缩的原始数据，因此它们比常规的块文件要大。Prometheus将至少保留3个预写日志文件，但是高流量服务器可能会看到三个以上的WAL文件，因为它需要保留至少两个小时的原始数据。</p>
<p>这些块会在后台被压缩成更大的块以节省磁盘，最大长度取决于 <code>storage.tsdb.max-block-duration</code> 参数的设置，默认为保留时间的 <code>10%</code>。<br>一般来说 <code>storage.tsdb.max-block-duration</code> = <code>storage.tsdb.min-block-duration</code> = <code>2h</code> 就相当于禁用了压缩功能，<br>但是别让它们低于 <code>2h</code>，否则有以下的问题：</p>
<ul>
<li>落盘过于频繁，这会很大程度影响 <code>Promethues</code> 的吞吐量。</li>
<li>由于 <code>WAL</code> 至少保留两个小时，所以这部分的内存是没办法释放的。</li>
</ul>
<p>参考<a target="_blank" rel="noopener" href="https://prometheus.io/docs/practices/remote_write/">Remote write tuning</a></p>
<h2 id="rate-vs-irate"><a href="#rate-vs-irate" class="headerlink" title="rate vs irate"></a>rate vs irate</h2><p>两者的决定性差别在于:</p>
<ul>
<li>rate 使用整个时间区间所有点计算出平均变化速率，它会削平峰值</li>
<li>irate 使用时间区间内最后的两个数据点作为变化速率</li>
</ul>
<p>从它们两者的计算公式我们可以得到以下推论：</p>
<ul>
<li>当选择的计算区间内仅仅包含两个数据点时，rate 和 irate 没有区别</li>
<li>我们使用 rate 来查看某个数据在较长一段时间内的变化趋势，它会消除一些细节防止影响趋势的展示</li>
<li>使用 irate 来查看某个数据在一段时间内的细小抖动和完整的变化。</li>
<li>使用 rate 时尽量选择较长的时间，而 irate 则反之（太长会丢失很多变化）</li>
</ul>
<h2 id="relabel-config-vs-metric-relabel-configs"><a href="#relabel-config-vs-metric-relabel-configs" class="headerlink" title="relabel_config vs metric_relabel_configs"></a>relabel_config vs metric_relabel_configs</h2><p><code>relabel_config</code> 发生在 <code>metric_relabel_configs</code>，通常用于挑选 target </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/prometheus/README/" data-id="ckizkw7u6000izolm7tebeatl" data-title="Prometheus" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-pprof/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/pprof/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.210Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/pprof/README/">简单易懂的 pprof 手册</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="简单易懂的-pprof-手册"><a href="#简单易懂的-pprof-手册" class="headerlink" title="简单易懂的 pprof 手册"></a>简单易懂的 pprof 手册</h1><p>推荐阅读</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000019222661">实战Go内存泄露</a></li>
<li><a target="_blank" rel="noopener" href="https://dave.cheney.net/high-performance-go-workshop/dotgo-paris.html">High Performance Go Workshop</a></li>
</ul>
<p>完整格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof &lt;format&gt; [options] [binary] &lt;source&gt; ...</span><br></pre></td></tr></table></figure>
<p>省略 <code>&lt;format&gt;</code> 可以使用交互式的控制台，或者换成为 <code>-http</code> 可以启动一个 web 服务器查看性能分析图</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -http [host]:[port] [options] [binary] &lt;source&gt; ...</span><br></pre></td></tr></table></figure>
<p><code>&lt;source&gt;</code> 支持三种格式：</p>
<ul>
<li>profile.pb.gz: 压缩的 profile 文件，可以通过 <code>-proto</code> 格式输出</li>
<li>pprof的 http 接口</li>
<li>legacy_profile： 遗留格式，不推荐</li>
</ul>
<p>pprof 的 http 服务的路径如 <code>/debug/pprof/&#123;res&#125;</code>, <code>res</code> 支持以下几种类型采样：</p>
<ul>
<li>allocs: 内存分配</li>
<li>blocks: 阻塞操作</li>
<li>cmdline: 显示程序启动命令</li>
<li>goroutine: 协程</li>
<li>heap: 堆内存信息</li>
<li>mutex: 锁争用信息</li>
<li>profile: cpu</li>
<li>threadcreat: 系统线程</li>
<li>trace: 程序运行跟踪信息</li>
</ul>
<p><em>allocs 和 heap 采样的信息一致，不过前者是所有对象的内存分配，而 heap 则是活跃对象的内存分配。</em></p>
<h2 id="采样相关"><a href="#采样相关" class="headerlink" title="采样相关"></a>采样相关</h2><p>你可以直接使用 <code>curl</code> 命令访问 http 服务获取原始采样信息，如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;127.0.0.1&#x2F;debug&#x2F;pprof&#x2F;goroutine &gt; goroutine.profile</span><br></pre></td></tr></table></figure>
<p>原始采样数据也可以作为 <code>&lt;source&gt;</code> 的数据源信息</p>
<p>内存分析时可以指定 <code>-sample_index</code>:</p>
<ul>
<li>inuse_space: 正在使用，尚未释放的空间</li>
<li>inuse_object: 正在使用，尚未释放的对象</li>
<li>alloc_space: 所有分配的空间，包含已释放的</li>
<li>alloc_objects:  所有分配的对象，包含已释放的</li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><ul>
<li>采样堆内存并输出 profile<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -proto http:&#x2F;&#x2F;127.0.0.1&#x2F;debug&#x2F;pprof&#x2F;heap</span><br></pre></td></tr></table></figure></li>
<li>采样堆内存并输出 profile ( 指定路径 )<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -proto -sample_index&#x3D;alloc_space -output xxx.pb.gz http:&#x2F;&#x2F;127.0.0.1&#x2F;debug&#x2F;pprof&#x2F;heap</span><br></pre></td></tr></table></figure></li>
<li>采样 CPU 30s 并输出 profile<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -proto http:&#x2F;&#x2F;127.0.0.1&#x2F;debug&#x2F;pprof&#x2F;profile?seconds&#x3D;5</span><br></pre></td></tr></table></figure></li>
<li>对比两个时间点的内存差值<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -http&#x3D;:8080 -base xxx.pb.gz xxx.pb.gz</span><br></pre></td></tr></table></figure></li>
<li>打开分析文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -http&#x3D;:8080 .&#x2F;xxx.pb.gz</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2></li>
<li>heap 只能展示堆上面的内存消耗而不能展示栈，所以当 goroutine 泄露时，你无法通过 heap 定位到</li>
<li>多用 <code>-base</code> 来对比不同时间点的增长 </li>
</ul>
<p>完整格式如下( go1.14.6 )</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line">usage:</span><br><span class="line"></span><br><span class="line">Produce output in the specified format.</span><br><span class="line"></span><br><span class="line">   pprof &lt;format&gt; [options] [binary] &lt;source&gt; ...</span><br><span class="line"></span><br><span class="line">Omit the format to get an interactive shell whose commands can be used</span><br><span class="line">to generate various views of a profile</span><br><span class="line"></span><br><span class="line">   pprof [options] [binary] &lt;source&gt; ...</span><br><span class="line"></span><br><span class="line">Omit the format and provide the &quot;-http&quot; flag to get an interactive web</span><br><span class="line">interface at the specified host:port that can be used to navigate through</span><br><span class="line">various views of a profile.</span><br><span class="line"></span><br><span class="line">   pprof -http [host]:[port] [options] [binary] &lt;source&gt; ...</span><br><span class="line"></span><br><span class="line">Details:</span><br><span class="line">  Output formats (select at most one):</span><br><span class="line">    -callgrind       Outputs a graph in callgrind format</span><br><span class="line">    -comments        Output all profile comments</span><br><span class="line">    -disasm          Output assembly listings annotated with samples</span><br><span class="line">    -dot             Outputs a graph in DOT format</span><br><span class="line">    -eog             Visualize graph through eog</span><br><span class="line">    -evince          Visualize graph through evince</span><br><span class="line">    -gif             Outputs a graph image in GIF format</span><br><span class="line">    -gv              Visualize graph through gv</span><br><span class="line">    -kcachegrind     Visualize report in KCachegrind</span><br><span class="line">    -list            Output annotated source for functions matching regexp</span><br><span class="line">    -pdf             Outputs a graph in PDF format</span><br><span class="line">    -peek            Output callers&#x2F;callees of functions matching regexp</span><br><span class="line">    -png             Outputs a graph image in PNG format</span><br><span class="line">    -proto           Outputs the profile in compressed protobuf format</span><br><span class="line">    -ps              Outputs a graph in PS format</span><br><span class="line">    -raw             Outputs a text representation of the raw profile</span><br><span class="line">    -svg             Outputs a graph in SVG format</span><br><span class="line">    -tags            Outputs all tags in the profile</span><br><span class="line">    -text            Outputs top entries in text form</span><br><span class="line">    -top             Outputs top entries in text form</span><br><span class="line">    -topproto        Outputs top entries in compressed protobuf format</span><br><span class="line">    -traces          Outputs all profile samples in text form</span><br><span class="line">    -tree            Outputs a text rendering of call graph</span><br><span class="line">    -web             Visualize graph through web browser</span><br><span class="line">    -weblist         Display annotated source in a web browser</span><br><span class="line"></span><br><span class="line">  Options:</span><br><span class="line">    -call_tree       Create a context-sensitive call tree</span><br><span class="line">    -compact_labels  Show minimal headers</span><br><span class="line">    -divide_by       Ratio to divide all samples before visualization</span><br><span class="line">    -drop_negative   Ignore negative differences</span><br><span class="line">    -edgefraction    Hide edges below &lt;f&gt;*total</span><br><span class="line">    -focus           Restricts to samples going through a node matching regexp</span><br><span class="line">    -hide            Skips nodes matching regexp</span><br><span class="line">    -ignore          Skips paths going through any nodes matching regexp</span><br><span class="line">    -mean            Average sample value over first value (count)</span><br><span class="line">    -nodecount       Max number of nodes to show</span><br><span class="line">    -nodefraction    Hide nodes below &lt;f&gt;*total</span><br><span class="line">    -noinlines       Ignore inlines.</span><br><span class="line">    -normalize       Scales profile based on the base profile.</span><br><span class="line">    -output          Output filename for file-based outputs</span><br><span class="line">    -prune_from      Drops any functions below the matched frame.</span><br><span class="line">    -relative_percentages Show percentages relative to focused subgraph</span><br><span class="line">    -sample_index    Sample value to report (0-based index or name)</span><br><span class="line">    -show            Only show nodes matching regexp</span><br><span class="line">    -show_from       Drops functions above the highest matched frame.</span><br><span class="line">    -source_path     Search path for source files</span><br><span class="line">    -tagfocus        Restricts to samples with tags in range or matched by regexp</span><br><span class="line">    -taghide         Skip tags matching this regexp</span><br><span class="line">    -tagignore       Discard samples with tags in range or matched by regexp</span><br><span class="line">    -tagshow         Only consider tags matching this regexp</span><br><span class="line">    -trim            Honor nodefraction&#x2F;edgefraction&#x2F;nodecount defaults</span><br><span class="line">    -trim_path       Path to trim from source paths before search</span><br><span class="line">    -unit            Measurement units to display</span><br><span class="line"></span><br><span class="line">  Option groups (only set one per group):</span><br><span class="line">    cumulative</span><br><span class="line">      -cum             Sort entries based on cumulative weight</span><br><span class="line">      -flat            Sort entries based on own weight</span><br><span class="line">    granularity</span><br><span class="line">      -addresses       Aggregate at the address level.</span><br><span class="line">      -filefunctions   Aggregate at the function level.</span><br><span class="line">      -files           Aggregate at the file level.</span><br><span class="line">      -functions       Aggregate at the function level.</span><br><span class="line">      -lines           Aggregate at the source code line level.</span><br><span class="line"></span><br><span class="line">  Source options:</span><br><span class="line">    -seconds              Duration for time-based profile collection</span><br><span class="line">    -timeout              Timeout in seconds for profile collection</span><br><span class="line">    -buildid              Override build id for main binary</span><br><span class="line">    -add_comment          Free-form annotation to add to the profile</span><br><span class="line">                          Displayed on some reports or with pprof -comments</span><br><span class="line">    -diff_base source     Source of base profile for comparison</span><br><span class="line">    -base source          Source of base profile for profile subtraction</span><br><span class="line">    profile.pb.gz         Profile in compressed protobuf format</span><br><span class="line">    legacy_profile        Profile in legacy pprof format</span><br><span class="line">    http:&#x2F;&#x2F;host&#x2F;profile   URL for profile handler to retrieve</span><br><span class="line">    -symbolize&#x3D;           Controls source of symbol information</span><br><span class="line">      none                  Do not attempt symbolization</span><br><span class="line">      local                 Examine only local binaries</span><br><span class="line">      fastlocal             Only get function names from local binaries</span><br><span class="line">      remote                Do not examine local binaries</span><br><span class="line">      force                 Force re-symbolization</span><br><span class="line">    Binary                  Local path or build id of binary for symbolization</span><br><span class="line">    -tls_cert             TLS client certificate file for fetching profile and symbols</span><br><span class="line">    -tls_key              TLS private key file for fetching profile and symbols</span><br><span class="line">    -tls_ca               TLS CA certs file for fetching profile and symbols</span><br><span class="line"></span><br><span class="line">  Misc options:</span><br><span class="line">   -http              Provide web interface at host:port.</span><br><span class="line">                      Host is optional and &#39;localhost&#39; by default.</span><br><span class="line">                      Port is optional and a randomly available port by default.</span><br><span class="line">   -no_browser        Skip opening a browser for the interactive web UI.</span><br><span class="line">   -tools             Search path for object tools</span><br><span class="line"></span><br><span class="line">  Legacy convenience options:</span><br><span class="line">   -inuse_space           Same as -sample_index&#x3D;inuse_space</span><br><span class="line">   -inuse_objects         Same as -sample_index&#x3D;inuse_objects</span><br><span class="line">   -alloc_space           Same as -sample_index&#x3D;alloc_space</span><br><span class="line">   -alloc_objects         Same as -sample_index&#x3D;alloc_objects</span><br><span class="line">   -total_delay           Same as -sample_index&#x3D;delay</span><br><span class="line">   -contentions           Same as -sample_index&#x3D;contentions</span><br><span class="line">   -mean_delay            Same as -mean -sample_index&#x3D;delay</span><br><span class="line"></span><br><span class="line">  Environment Variables:</span><br><span class="line">   PPROF_TMPDIR       Location for saved profiles (default $HOME&#x2F;pprof)</span><br><span class="line">   PPROF_TOOLS        Search path for object-level tools</span><br><span class="line">   PPROF_BINARY_PATH  Search path for local binary files</span><br><span class="line">                      default: $HOME&#x2F;pprof&#x2F;binaries</span><br><span class="line">                      searches $name, $path, $buildid&#x2F;$name, $path&#x2F;$buildid</span><br><span class="line">   * On Windows, %USERPROFILE% is used instead of $HOME</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/pprof/README/" data-id="ckizkw7u2000dzolm2yxx7scu" data-title="简单易懂的 pprof 手册" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-openresty-note/cpu-setting-in-cloudnative/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/openresty-note/cpu-setting-in-cloudnative/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.170Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Nginx在云上环境的CPU最佳实践"><a href="#Nginx在云上环境的CPU最佳实践" class="headerlink" title="Nginx在云上环境的CPU最佳实践"></a>Nginx在云上环境的CPU最佳实践</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><a href="#%E8%83%8C%E6%99%AF">背景</a></li>
<li><a href="#Nginx%E7%9A%84CPU%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE">Nginx的CPU相关设置</a></li>
<li><a href="#k8s%E7%9A%84CPU%E7%AD%96%E7%95%A5">k8s的CPU策略</a></li>
<li><a href="#%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94">方案对比</a></li>
<li><a href="#%E7%BB%93%E8%AE%BA">结论</a></li>
</ul>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>最近有用户反馈 <a target="_blank" rel="noopener" href="https://github.com/apache/apisix">ApacheAPISIX</a> 在云原生环境下存在几个问题：</p>
<ul>
<li>无法获取容器准确核数</li>
<li>配置了多核的情况下无法完全利用</li>
</ul>
<p>这里先简单介绍项目相关的情况，APISIX 是一个基于 Openresty 的开源网关。而 Openresty 其实就是 Nginx + LuaJIT，那么我们要调查问题其实跟 Nginx 是脱不开关系的。</p>
<h3 id="Nginx的CPU相关设置"><a href="#Nginx的CPU相关设置" class="headerlink" title="Nginx的CPU相关设置"></a>Nginx的CPU相关设置</h3><p>首先看看第一个问题：<strong>无法获取容器准确核数</strong>，这个问题的起因是因为在 Nginx 配置中使用了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">worker_processes auto;</span><br></pre></td></tr></table></figure>
<p><code>auto</code> 意味 Nginx 会自动获取 CPU 核数，然后根据核数创建 worker。不幸的是，在容器当中它获取到的是 <strong>母机的核数</strong> 导致 Nginx 会在容器中创建数十个甚至上百个 worker，多个 worker 间的资源竞争和上下文切换都会降低它的性能。<br>为了核验 Nginx 是否真的获取的是母机核数，我翻了下 Nginx 相关的代码，截取核心片段如下：<br>src/os/unix/ngx_posix_init.c</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ngx_config.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ngx_core.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;nginx.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">ngx_int_t</span>   ngx_ncpu;</span><br><span class="line"><span class="keyword">ngx_int_t</span>   ngx_max_sockets;</span><br><span class="line"><span class="keyword">ngx_uint_t</span>  ngx_inherited_nonblocking;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> (NGX_HAVE_SC_NPROCESSORS_ONLN)</span></span><br><span class="line">    <span class="keyword">if</span> (ngx_ncpu == <span class="number">0</span>) &#123;</span><br><span class="line">        ngx_ncpu = sysconf(_SC_NPROCESSORS_ONLN);</span><br></pre></td></tr></table></figure>
<p>查看 <a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man3/sysconf.3.html">sysconf</a> 的文档发现底层调用的 <a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man3/get_nprocs_conf.3.html"> get_nprocs_conf(3)</a>, 继续查看它的<a target="_blank" rel="noopener" href="https://code.woboq.org/userspace/glibc/sysdeps/unix/sysv/linux/getsysstats.c.html#__get_nprocs_conf">源码</a>，核心片段如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* On some architectures it is possible to distinguish between configured</span></span><br><span class="line"><span class="comment">   and active cpus.  */</span></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">__get_nprocs_conf (<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">/* XXX Here will come a test for the new system call.  */</span></span><br><span class="line">  <span class="comment">/* Try to use the sysfs filesystem.  It has actual information about</span></span><br><span class="line"><span class="comment">     online processors.  */</span></span><br><span class="line">  DIR *dir = __opendir (<span class="string">&quot;/sys/devices/system/cpu&quot;</span>);</span><br><span class="line">  <span class="keyword">if</span> (dir != <span class="literal">NULL</span>)</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure>
<p>注意这个路径 <code>/sys/devices/system/cpu</code>，随便进入到一个容器中，ls 一下它你会发现它是母机的CPU信息，类似下面：<br><image src="./images/cpulist.png"></p>
<p>OK，第一个问题至此已确认完毕，我们先看看第二个问题再讨论解决方案，因为看上去它们应该是关联的。</p>
<h3 id="k8s的CPU策略"><a href="#k8s的CPU策略" class="headerlink" title="k8s的CPU策略"></a>k8s的CPU策略</h3><p>关于第二个问题：<strong>配置了多核的情况下无法完全利用</strong>，直觉这个问题跟另一个 Nginx 的配置参数有关：<code>worker_cpu_affinity</code>，它可以指定 Nginx绑定到几号核。手动指定的场景我们直接跳过，通常我们都是使用 <code>auto</code> 参数。看下当设置 auto 时，Nginx 会怎么绑定CPU，核心代码片段如下：<br>src/core/nginx.c</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ngx_strcmp(value[<span class="number">1</span>].data, <span class="string">&quot;auto&quot;</span>) == <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cf-&gt;args-&gt;nelts &gt; <span class="number">3</span>) &#123;</span><br><span class="line">        ngx_conf_log_error(NGX_LOG_EMERG, cf, <span class="number">0</span>,</span><br><span class="line">                           <span class="string">&quot;invalid number of arguments in &quot;</span></span><br><span class="line">                           <span class="string">&quot;\&quot;worker_cpu_affinity\&quot; directive&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> NGX_CONF_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ccf-&gt;cpu_affinity_auto = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    CPU_ZERO(&amp;mask[<span class="number">0</span>]);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; (<span class="keyword">ngx_uint_t</span>) ngx_min(ngx_ncpu, CPU_SETSIZE); i++) &#123;</span><br><span class="line">        CPU_SET(i, &amp;mask[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    n = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    n = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到CPU的绑核策略是顺序从低位到高位，这样做在普通的物理机本来没什么问题，但是在 k8s 的环境下就不行了，原因有两个：</p>
<ul>
<li>绑核动作需要特权执行，通常 POD 是没有权限的</li>
<li>在于 k8s 在<code>static</code> 策略下本来就会对 limit 为整数的 <code>Guaranteed</code> POD进行绑核处理，可以参考 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/tasks/administer-cluster/cpu-management-policies/">控制节点上的 CPU 管理策略</a> 。</li>
</ul>
<p>所以云上应用都不建议再去应用进行绑核操作。</p>
<p>回过头来说 Nginx 自动从低位CPU绑到高位的这个操作，没有特权的情况会怎样？上面的代码片段我们看到它使用了 <code>CPU_SET</code> 这个系统调用，相关的方法签名如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void CPU_SET(int cpu, cpu_set_t *set);</span><br></pre></td></tr></table></figure>
<p>意味着无论绑核成功或失败，<strong>程序都得不到响应</strong>。为了验证这个结论，我们创建一个 Nginx 应用( 1c1g )，然后在容器执行以下命令查看绑定的核：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sh-4.2# cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuset&#x2F;cpuset.cpus</span><br><span class="line">45</span><br></pre></td></tr></table></figure>
<p>可以看到绑定到了第45号核(由0开始)，在母机上执行 <code>htop</code> 可以看到这里的第46号核(由1开始)，完全没有使用率：<br><image src="./images/htop-before.png"></p>
<p>开始执行压测后：<br><image src="./images/htop-after.png"></p>
<p>很明显，Nginx 绑核并没有成功，容器依然绑定在原来的CPU上。<br>通常来说，没有特殊原因都不建议云上应用再去执行绑核操作，保持不变即可。</p>
<h3 id="方案对比"><a href="#方案对比" class="headerlink" title="方案对比"></a>方案对比</h3><p>开始我以为多核无法利用的情况，是容器绑定的核与应用绑定的核只有小部分重叠，所以才导致无法有效利用。但现在看来，没有 <strong>特权</strong> 的 Nginx 甚至连绑核都做不到，那么我们要继续考虑其他可能的问题。<br>列举以下情况：<br>| 情况 | QPS | CPU使用率 |<br>| — | — | — |<br>| 1c2g-1workers | 10959.22 | 100% |<br>| 2c4g-1workers | 11845.91 | 100% |<br>| 2c4g-2workers | 16975.04 | 200% |<br>| 1c2g-1workers * 2 | 22492.83 | 200% |<br>| 4c8g-2workers | 20506.10 | 200% |<br>| 4c8g-4workers | 31012.40 | 400% |<br>| 1c2g-1workers * 4 | 51720.11 | 400% |<br>| 1.001c2g-1workers * 4 | 47501.16 | 401% |</p>
<p>这里我们可以看到使用多个单核的容器会比使用多核的单个容器具有更高的吞吐量，可能的原因有两点：</p>
<ul>
<li>多个worker间存在资源竞争</li>
<li>单核容器由于可用核只有一个，所以相当于进行了绑核操作</li>
</ul>
<p>为了排除第二个原因的影响，我补充图表中的最后一个用例(1.001c2g-1workers * 4)，这个用例中由于cpu不是整数核，所以没有分配独占cpu。可以发现它的吞吐量下降了8%左右，证明绑核还是有效果的。</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>通过以上的实验，我们可以得出几个关键点：</p>
<ul>
<li>worker 少于 cpu 数量时无法充分利用 cpu</li>
<li>云上的 Nginx 最好使用 <strong>单核多容器</strong> 的部署模式，这样可以充分利用k8s的cpu策略进行绑核，单worker也是Nginx的推荐设置，如果要设置多个 worker，那么不要使用 <code>auto</code> 参数，获取到的将会是母机核数</li>
<li>如果要使用多核的情况下，尽量不要使用过大的cpu数量，推荐最多8个，否则 worker 数量过多会造成大量资源浪费在处理竞争上</li>
<li>云上不要使用 <code>worker_cpu_affinity=auto</code>，因为除了需要特权外，顺位绑核的操作不一定能绑定到 k8s 分配的独占核，极端情况下还会导致不可用，所以在云上环境多结合 k8s 的 CPU策略 来使用才是最佳实践</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/openresty-note/cpu-setting-in-cloudnative/README/" data-id="ckizkw7u7000kzolm0koa8sej" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-openresty-note/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/openresty-note/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.164Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/openresty-note/README/">Openresty 笔记</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Openresty-笔记"><a href="#Openresty-笔记" class="headerlink" title="Openresty 笔记"></a>Openresty 笔记</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Openresty 是一个国人将LuaJIT嵌入Nginx进程进而可以使用Nginx来进行开发高性能的Web框架。<br>入门的简介可以参考这个文档，<a target="_blank" rel="noopener" href="https://juejin.im/entry/5ba3abd65188255c8a05f69c">OpenResty 不完全指南</a></p>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ul>
<li>很多 lua 的内置函数都是全局变量，把它注册到本地来使用，性能会更好。</li>
<li>注意 Openresty 当中请求域名时会使用 Nginx 配置的 Dns 服务器，搜索 <code>resolver</code> 了解更多细节（Nginx 实现了一套内置的 DNS 解析）</li>
<li>Openresty 中默认不读取 body ，可以通过以下方式打开<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen    80;</span><br><span class="line"></span><br><span class="line">        # 默认读取 body</span><br><span class="line">        lua_need_request_body on;</span><br><span class="line"></span><br><span class="line">        location &#x2F;test &#123;</span><br><span class="line">            content_by_lua_block &#123;</span><br><span class="line">                local data &#x3D; ngx.req.get_body_data()</span><br><span class="line">                ngx.say(&quot;hello &quot;, data)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
或者局部开启<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ngx.req.read_body()</span><br></pre></td></tr></table></figure></li>
<li>Openresty 有时 <code>ngx.req.get_body_data()</code> 读取不到数据时因为已经被转储到文件了，还需要从 <code>ngx.req.get_body_file</code> 中读取</li>
<li>Nginx 有两个比较关键的参数 <a target="_blank" rel="noopener" href="http://nginx.org/en/docs/http/ngx_http_core_module.html#client_body_buffer_size">client_body_buffer_size</a> 和 <a target="_blank" rel="noopener" href="http://nginx.org/en/docs/http/ngx_http_core_module.html#client_max_body_size">client_max_body_size</a> ，前者控制缓冲区大小，大于这个部分的请求体会被转储为临时文件（文档上说明为部分或全部，但目前观测到的情况一般都是全部转储）；后者控制能接受的最大请求体，大于会被拒绝( 413 Request Entity Too Large)</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/openresty-note/README/" data-id="ckizkw7u3000ezolm20kjea81" data-title="Openresty 笔记" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-net-analysis/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/net-analysis/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.158Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/net-analysis/README/">网络分析</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="网络分析"><a href="#网络分析" class="headerlink" title="网络分析"></a>网络分析</h1><p>在 <code>linux</code> 上我们可以使用 <code>tcpdump</code> 来分析流量包，<code>wireshark</code> 分析包，<code>strace</code> 查看进程调用。<br><code>fiddler</code> 用于分析 http 协议，<code>wireshark</code> 用于分析 tcp/udp 的网络封包</p>
<h2 id="https-包抓取"><a href="#https-包抓取" class="headerlink" title="https 包抓取"></a>https 包抓取</h2><p>网络流量的这些工具为了能够解析 https 的包，通常都是自己签发证书，然后让系统信任自己证书，以作为中间人去转发、解析 https 流量。<br>如果仅仅只是为了代理 https 流量而不解析，可以使用 http 的隧道协议，使用 <code>CONNECT</code> method 去连接代理服务器，然后代理服务自动转发握手请求，相当于客户端直接与目标服务连接。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/net-analysis/README/" data-id="ckizkw7u0000bzolmga500p7a" data-title="网络分析" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-mutually-exclusive-and-idempotency/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/mutually-exclusive-and-idempotency/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.136Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/mutually-exclusive-and-idempotency/README/">互斥性与幂等性</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="互斥性与幂等性"><a href="#互斥性与幂等性" class="headerlink" title="互斥性与幂等性"></a>互斥性与幂等性</h2><p>我觉得这两个特性是在系统分析和设计时必须考虑的问题。开始之前，先简单解释下两者的概念。</p>
<h3 id="什么是互斥性"><a href="#什么是互斥性" class="headerlink" title="什么是互斥性"></a>什么是互斥性</h3><p>要解释互斥性就不得不先提一下 <strong>临界资源</strong>，引用百科的介绍。</p>
<blockquote>
<p>一次仅允许一个进程使用的资源称为临界资源。</p>
</blockquote>
<p>很显然，当多方共享临界资源时，那么这些使用方是互斥的。<br>举一些场景：</p>
<ul>
<li>多个人同时修改同一个文档</li>
<li>多个线程一起修改一个并发不安全的Map</li>
</ul>
<p>假设程序不保证互斥性：<br>让大家一起修改，那么：</p>
<ul>
<li><strong>场景一</strong>：最后只会保留最后一个处理的修改，其他的修改都会丢失</li>
<li><strong>场景二</strong>：在多线程同时写入内存时会因为竞争关系出现数据错乱，有兴趣的同学可以看下这篇文章 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/93336747">为什么你的并发程序不安全</a>。</li>
</ul>
<p>这些显然是我们不愿看见的情况，所以保证互斥性对于临界资源的使用是非常重要的，保证互斥性的过程其实也是保证<strong>并发安全性</strong>的过程。</p>
<p>这里再多说下一些进程内的情况，比如多个线程对一个变量的读写，一写多读，需不要保证互斥性？<br>答案是要。<br>这里涉及到两个原因：</p>
<ul>
<li>哪怕你的语句是一条汇编的原子操作(比如MOV xxxx, xxxx) 都不一定是原子操作。</li>
<li>多线程操作时，可能位于不同CPU上执行，修改对其他在其他CPU上执行的线程来说并不是马上可见的</li>
</ul>
<p>基于以上原因，那怕是对一个bit的操作，也需要考虑互斥性。</p>
<h3 id="什么是幂等性"><a href="#什么是幂等性" class="headerlink" title="什么是幂等性"></a>什么是幂等性</h3><p>幂等原本是数学的概念，表示某个运算执行任意多次与一次的结果相同。<br>后来引用到系统设计中，指具备该性质的接口在相同的参数下，调用一次与多次结果相同。<br>显然，有一些类别的接口天生就是幂等的，比如 <strong>查询</strong> 和 <strong>删除</strong>。<br>幂等性的重要性在于消除重复提交来带的副作用。<br>考虑下面的场景</p>
<ul>
<li>某个人在同一页面多次提交对文档的修改（假设页面没有二次防押）</li>
<li>某个秒杀环节中，通过消息中间件来分摊处理的压力，但是消息中间件由于各种不可控因素投递了两次相同的消息</li>
</ul>
<p>假设接口不保证幂等性，那么：</p>
<ul>
<li><strong>场景一</strong>：加大了存储系统的负担，如果同一时间很多这样操作的用户，可能会引发服务雪崩。</li>
<li><strong>场景二</strong>: 如果消费的逻辑没有保证幂等，那么就会生成两条相同的订单</li>
</ul>
<h2 id="互斥性的解决方案"><a href="#互斥性的解决方案" class="headerlink" title="互斥性的解决方案"></a>互斥性的解决方案</h2><p>引用下在美团技术沙龙的 <a target="_blank" rel="noopener" href="https://tech.meituan.com/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis.html">分布式系统互斥性与幂等性问题的分析与解决</a> 出现的一句话</p>
<blockquote>
<p>基本上所有的并发模式在解决线程冲突问题的时候，都是采用序列化访问共享资源的方案。</p>
</blockquote>
<p>我觉得这句话很棒，在 &lt;&lt;七周七并发模式&gt;&gt; 书中出现的并发模式比如 <strong>CSP</strong>, <strong>Actor</strong>其实本质上也都是把对共享资源的请求串行化了，比如 <strong>CSP</strong> 是将请求都放入 <strong>Channel</strong> 中，而 <strong>Actor</strong> 则放入了 <strong>MailBox</strong>。</p>
<p>基于这个前提，我们来看下保证互斥性的一些解决方案：</p>
<h3 id="多线程-协程-下的互斥性"><a href="#多线程-协程-下的互斥性" class="headerlink" title="多线程(协程)下的互斥性"></a>多线程(协程)下的互斥性</h3><p>这个应该是我们编程时最常见的情况了，考虑以下的场景：</p>
<ul>
<li>线程(协程)A和B，共享一个静态Map(非线程安全的)</li>
</ul>
<p>在这个场景下，A和B如果不满足互斥性，那么就有可能产生预料之外的结果。因为我们的Map是线程不安全的。<br>要保证互斥性，有以下方式</p>
<ul>
<li>锁</li>
<li>CSP(go)</li>
<li>其他并发模型，比如Actor(erlang), 函数式(clojure)，由于笔者没有实践项目经验，此处不讨论，有兴趣的读者可以自行了解。</li>
</ul>
<p><em>注意：并发模型只是一种思想，括号内表示该语言原生支持此并发模型。就算没有原生支持该模型的语言，也几乎都有社区提供了类库实现并发模型。</em></p>
<h4 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h4><p>基本上大多数语言都提供了锁的机制，常见的锁可以分为以下两类</p>
<ul>
<li>互斥锁</li>
<li>读写锁</li>
</ul>
<p><strong>互斥锁</strong><br>互斥锁表示在使用方占有资源时，拒绝其他请求方的 <strong>读</strong> 和 <strong>写</strong>，互斥锁当然很保险，不过假设在读多写少的场景中，我们当然不希望每次都会因为<strong>读操作</strong>而阻塞其他请求方的<strong>读操作</strong>，因为他们都是无副作用的，所以诞生了下面的<strong>读写锁</strong>。<br>这里以<strong>Go</strong>语言为例，代码如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> demo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;sync&quot;</span></span><br><span class="line">	<span class="string">&quot;testing&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">	_globalMap = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;&#125;</span><br><span class="line">	_mux       = sync.Mutex&#123;&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mutexReadValue</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	_mux.Lock()</span><br><span class="line">	<span class="keyword">defer</span> _mux.Unlock()</span><br><span class="line">	<span class="keyword">return</span> _globalMap[key]</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mutexWriteValue</span><span class="params">(key, value <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	_mux.Lock()</span><br><span class="line">	<span class="keyword">defer</span> _mux.Unlock()</span><br><span class="line">	_globalMap[key] = value</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestMutex</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">	workers := <span class="number">1000000</span></span><br><span class="line">	wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; workers; i++ &#123;</span><br><span class="line">		wg.Add(<span class="number">1</span>)</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			mutexReadValue(<span class="string">&quot;key&quot;</span>)</span><br><span class="line">			<span class="comment">// do something</span></span><br><span class="line">			mutexWriteValue(<span class="string">&quot;key&quot;</span>, <span class="string">&quot;value&quot;</span>)</span><br><span class="line">			wg.Done()</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>读写锁</strong><br>读写锁顾名思义分成了读锁和写锁。<br>读锁允许多个请求方同时获取，而写锁是排他的，同一时间只允许同一个请求方获得写锁。当资源存在读锁时，写锁只能等待读锁释放才能获取，反之亦然。</p>
<p><em>读写锁解决了互斥锁在读多写少的情况下，所造成的不必要阻塞</em><br>这里以<strong>Go</strong>语言为例，代码如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> demo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;sync&quot;</span></span><br><span class="line">	<span class="string">&quot;testing&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">	_rwglobalMap = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;&#125;</span><br><span class="line">	_rwmux       = sync.RWMutex&#123;&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">rwmutexReadValue</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	_rwmux.RLock()</span><br><span class="line">	<span class="keyword">defer</span> _rwmux.RUnlock()</span><br><span class="line">	<span class="keyword">return</span> _globalMap[key]</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">rwmutexWriteValue</span><span class="params">(key, value <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	_rwmux.Lock()</span><br><span class="line">	<span class="keyword">defer</span> _rwmux.Unlock()</span><br><span class="line">	_globalMap[key] = value</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestRwMutex</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">	workers := <span class="number">1000000</span></span><br><span class="line">	wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; workers; i++ &#123;</span><br><span class="line">		wg.Add(<span class="number">1</span>)</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			rwmutexReadValue(<span class="string">&quot;key&quot;</span>)</span><br><span class="line">			<span class="comment">// do something</span></span><br><span class="line">			rwmutexWriteValue(<span class="string">&quot;key&quot;</span>, <span class="string">&quot;value&quot;</span>)</span><br><span class="line">			wg.Done()</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="CSP"><a href="#CSP" class="headerlink" title="CSP"></a>CSP</h4><p>CSP( Communicating sequential processes ) 是一种指导并发编程的思想，有关其详细的介绍参见 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Communicating_sequential_processes">Wiki</a>，这里只简单说下，CSP的核心思想在于让各个 <code>worker(进程、线程or协程)</code> 使用<code> Channel</code> 来通信而避免共享内存。有人会疑惑，通过通信来交换信息怎么就能够避免共享内存了？<br>画了一个简单的草图如下：</p>
<p>可以看见，对临界资源(Critical Resource)的访问只有唯一的一个worker，我这里把它叫做<code>guard</code>。其他所有worker对临界资源的访问(查询or更新)都是通过与 guard 通信来完成，这样其实对临界资源的访问自然而然就被序列化为串行的了。<br>还是以<strong>Go</strong>语言为例，我们解决刚才场景中问题的代码如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>值得注意的是，代码里面实现的这种模式其实效率并没有直接加锁的性能更好，因为这里把读取也串行化了，并且针对每一个读取的请求都新创建一个Channel来传送返回值。所以代码还有很多优化空间，这里只是想展示下如何使用<code>CSP</code>来避免共享内存。但并不是所有场景下<code>CSP</code>或者<code>Actor</code>都优于传统的锁模式，还请注意场景的选择。</p>
<h3 id="多进程-相同or不同主机-下的互斥性"><a href="#多进程-相同or不同主机-下的互斥性" class="headerlink" title="多进程( 相同or不同主机 )下的互斥性"></a>多进程( 相同or不同主机 )下的互斥性</h3><p>这种情况相对来说在业务侧会比较常见的，回到我们最开始提出的问题：</p>
<ul>
<li>多个人同时修改同一个文档</li>
</ul>
<p>在这种情况下，有以下几个方式来保证互斥性：</p>
<ul>
<li>乐观锁</li>
<li>悲观锁</li>
</ul>
<p><del>其实还有别的一些方法来保证互斥性，比如 <code>PV操作</code> ，但我这里只想讨论一些通更用的解决方案</del></p>
<h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p>乐观锁的思想很简单，就是为我们的资源信息添加一个版本字段，每次更新时都更新这个字段，当更新时发现版本信息不匹配时，拒绝本次更新。<br>很多时候最简单的乐观锁实现方法就是新增一个<code>更新时间</code>的字段，更新时发现更新时间已经变化时则拒绝。</p>
<p>在这个场景下，我们可以有如下解决方式：<br>1、A 与 B 同时开始编辑文档<br>2、A 先保存文档<br>3、当 B 保存文档时发现更新时间与自己加载文档时不同了，此时保存失败</p>
<p>至于后面要不要自动合并 B 的修改，取决于业务。</p>
<h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4><p>悲观锁的思想也很简单，当上一个更新没有完毕时，拒绝下一个更新。<br>从技术角度来说，我们可以使用 <code>分布式锁</code> 来实现悲观锁，当某个使用者获得文档的锁才能编辑文档。</p>
<p>在这个场景下，我们可以：<br>1、A 与 B 同时开始编辑文档<br>2、A 率先获得锁，A 开始正常编辑<br>3、B 争抢锁失败，提示有人正在编辑，等待其他人编辑完毕</p>
<p>关于 <code>分布式锁</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/mutually-exclusive-and-idempotency/README/" data-id="ckizkw7tz0009zolmcumxh76x" data-title="互斥性与幂等性" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-microservice-best-practice/distributed-transaction/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/microservice-best-practice/distributed-transaction/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.130Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/microservice-best-practice/distributed-transaction/README/">分布式事务笔记</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="分布式事务笔记"><a href="#分布式事务笔记" class="headerlink" title="分布式事务笔记"></a>分布式事务笔记</h1><p>分布式事务的常见解决方案：</p>
<ul>
<li>2PC: perpare + commit</li>
<li>3PC: can_commit + pre_commit + do_commit</li>
<li>TCC: try + confirm + cancel</li>
<li>Saga: Events/Choreography or Command/Orchestration</li>
<li>本地消息表: local + event</li>
</ul>
<h2 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h2><p>2PC 由协调器通知各个事务参与者，由 <code>perpare</code> 与 <code>commit</code> 两个阶段组成，前者通知所有参与者预备事务，后者通知参与者真实提交事务。如果有参与者在 <code>prepare</code> 阶段失败，那么会通知所有参与者回滚。</p>
<p>优点:</p>
<ul>
<li>步骤少，简单</li>
</ul>
<p>缺点：</p>
<ul>
<li>协调器单点故障</li>
<li>会阻塞其他参与者的事务</li>
<li><code>commit</code> 阶段可能出现消息丢失</li>
</ul>
<h2 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a>3PC</h2><p>3PC 在 2PC 的基础上增加了各个参与者的超时时间，如果参与者在超时是时间内没有相应，那么视为失败。3PC 依然没有解决 <code>commit</code> 消息丢失的问题。</p>
<h2 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h2><p>TCC 相当于 3PC 的完善，除了超时机制外，还存在 <code>cancel</code> 步骤，意味着可以在 <code>commit</code> 失败后进行补偿。</p>
<h2 id="Saga"><a href="#Saga" class="headerlink" title="Saga"></a>Saga</h2><p>Saga 是一种长活事务的设计模式( Long-live transaction )，它基于 1978 年的一篇论文，主要有两种实现：Events/Choreography or Command/Orchestration<br>可以参考：<a target="_blank" rel="noopener" href="https://blog.couchbase.com/saga-pattern-implement-business-transactions-using-microservices-part/">saga-pattern-implement-business-transactions-using-microservices-part</a>、<br><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/architecture/%E3%80%82reference-architectures/saga/saga">saga</a>。</p>
<p>这里说一些需要注意的点：</p>
<ul>
<li><code>Choreography</code> 与 <code>Orchestration</code> 都有编排的意思，但是前者是不需要 <code>协调器(Orchestrator)</code> 的角色，都是参与者通过 <code>事件</code> 相互协作。参考 <a target="_blank" rel="noopener" href="https://medium.com/ingeniouslysimple/choreography-vs-orchestration-a6f21cfaccae">choreography-vs-orchestration</a></li>
<li>微软的 <a target="_blank" rel="noopener" href="https://docs.microsoft.com/zh-cn/dotnet/architecture/microservices/architect-microservice-container-applications/asynchronous-message-based-communication">基于容器化的微服务架构设计</a> 极力推荐服务间通过异步消息来通信，其实就是 <code>Events/Choreography</code> 模式的实现。</li>
<li><code>Command/Orchestration</code> 模式可以将 <code>协调器</code> 角色集成到调用者服务中，也可以共用一个 <code>中心协调器</code>，一般更推荐前一种模式，除非业务中存在大量类似需求。两者都需要注意多个实例时可能会存在多次执行的问题，所以一般都会涉及选主操作。</li>
<li><code>Command/Orchestration</code> 模式下如果将 <code>协调器</code> 集中到调用者服务时，需要考虑多个副本间的竞争关系。如果使用 <code>k8s</code> 集群，可以通过 <code>Sidecar</code> 方式来进行 Leader选举 从而轻松解决竞争问题，参考 <a target="_blank" rel="noopener" href="https://github.com/kubernetes-retired/contrib/tree/master/election">contrib/election</a>。</li>
<li><code>Events/Choreography</code> 应该作为系统首选方案，只有事务涉及服务太多( &gt; 4 )的情况再考虑 <code>Command/Orchestration</code>。</li>
<li><code>Events/Choreography</code> 要注意推送事件失败时的重试与补偿机制，需要的情况下可以使用 <code>本地消息表</code> 模式</li>
<li><code>Saga</code> 有两种错误恢复机制： <code>BackwordRecovery</code> 与 <code>ForwardRecovery</code>，前者指当某个参与者失败时，逆序对所有参与者调用补偿操作，这意味着这个事务的所有参与者都要实现一个补偿操作；而<code>ForwardRecovery</code> 则会重新对参与者发送请求，直到其成功，所以要求操作必须 <code>幂等</code>，由于这种恢复机制会假设永远成功，所以不需要实现补偿操作。</li>
<li>常用搭配：<ul>
<li><code>Events/Choreography</code> + <code>ForwardRecovery</code>: 实现最为简洁，应对事务复杂度较低，可以容忍实时性下限过低的场景</li>
<li><code>Command/Orchestration</code> + <code>BackwordRecovery</code>: 实现最为复杂，应对复杂事务与无法容忍实时性下限过低的场景</li>
</ul>
</li>
</ul>
<h2 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a>本地消息表</h2><p>这是 <code>eBay</code> 的一种设计模式，用于确保消息推送时的一致性。<br>通常情况调用服务很难保证 <code>提交自身事务</code> 与 <code>推送消息</code> 两者是强一致的，你很难保证网络不出问题，所以这种情况可以采用 <code>本地消息表</code> 模式，在本地存储中新建一个消息表，将需要发送的消息与事务数据放入同一个事务中落库，再异步发送消息，这样可以保证两个动作的强一致。</p>
<p>可以把这种模式作为 <code>Events/Choreography</code> 的一个补充，虽然我觉得多数情况有重试和补偿机制已经足够了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/microservice-best-practice/distributed-transaction/README/" data-id="ckizkw7u7000jzolmdju80z8l" data-title="分布式事务笔记" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-microservice-best-practice/distributed-consistence/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/microservice-best-practice/distributed-consistence/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.124Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/microservice-best-practice/distributed-consistence/README/">分布式一致性</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="分布式一致性"><a href="#分布式一致性" class="headerlink" title="分布式一致性"></a>分布式一致性</h1><p>目前主流算法如下：</p>
<ul>
<li>Paxos(  ): 共识算法，实现最为复杂，但是最为全面</li>
<li>Raft( ETCD, TiDB ): 基于 Paxos 的简化</li>
<li>ZAB( Zookeeper ): 基于 Paxos 的简化，类似 Raft</li>
<li>Gossip: 共识算法，利用节点传播来达到一致性</li>
<li>Bully: 选举算法</li>
</ul>
<h2 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/microservice-best-practice/distributed-consistence/README/" data-id="ckizkw7u5000gzolmfsqdbn3a" data-title="分布式一致性" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-microservice-best-practice/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/microservice-best-practice/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.119Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/microservice-best-practice/README/">微服务最佳实践</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="微服务最佳实践"><a href="#微服务最佳实践" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h1><h2 id="一定要做到的点"><a href="#一定要做到的点" class="headerlink" title="一定要做到的点"></a>一定要做到的点</h2><ul>
<li>每个请求一定要有 <code>request-id</code>，一般由调用方生成，如果你是在推动一个遗留项目，那么可以在网关或者<code>AOP</code>层去生成它，这样才能够在繁杂的日志中找到特定的请求信息。建议由 <code>uuid</code> 或者 雪花算法生成。</li>
<li>请求日志和错误日志分离，这么是因为这两者具有完全不同的关注点，且前者格式相对固定。分离他们可以在清洗日志时使用不同的格式。</li>
<li>如果你们的系统引入了调用链追踪，那么可以使用 <code>request-id</code> 作为 <code>trace-id</code>。</li>
<li>对于每一个资源的操作都应有反馈，比如删除不存在的资源或者创建同名的资源，我们都应该返回特定的错误码，通常可以使用三类: <code>NotFoundError</code>, <code>ConflictError</code>, <code>InternalError</code></li>
</ul>
<h2 id="框架选择"><a href="#框架选择" class="headerlink" title="框架选择"></a>框架选择</h2><ul>
<li>选择什么框架其实不是很重要，建议把代码构建成框架无关的形式，一般情况下可以使用一些抽象中间件完成</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/microservice-best-practice/README/" data-id="ckizkw7u2000czolm9b71dyvk" data-title="微服务最佳实践" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-load-test/wrt-usage/README" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/12/22/load-test/wrt-usage/README/" class="article-date">
  <time class="dt-published" datetime="2020-12-22T05:53:19.113Z" itemprop="datePublished">2020-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/12/22/load-test/wrt-usage/README/">Wrk</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Wrk-用法"><a href="#Wrk-用法" class="headerlink" title="Wrk 用法"></a>Wrk 用法</h1><h2 id="Wrk是什么"><a href="#Wrk是什么" class="headerlink" title="Wrk是什么"></a>Wrk是什么</h2><p>wrk是一个开源的http的压测工具，它封装了很多开源项目的，比如<code>redis</code>的<code>ae</code>( <em>一个事件循环的非阻塞网络库，底层封装了 epoll 和 kqueue</em>) 和 <code>nginx</code> 的 <code>http-parser</code>。基于这些优秀的开源项目，所以它的性能相当高。不过也因为它用了<code>epoll</code>和<code>kqueue</code>的原因，所以目前只支持<code>linux</code>平台。<br>同时还集成了<code>LuaJIT</code>，所以可以自己写Lua脚本，放在 <code>/scripts</code> 目录下。<a target="_blank" rel="noopener" href="https://github.com/wg/wrk">点击这里</a> 访问它的 Github。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>在Github的Release中下载最新版解压即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;wg&#x2F;wrk&#x2F;archive&#x2F;4.1.0.tar.gz .&#x2F;</span><br><span class="line">tar -xzvf .&#x2F;4.1.0.tar.gz</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<p>安装后自行选择是否是否将二进制文件放入<code>$PATH</code>中</p>
<h2 id="基础用法"><a href="#基础用法" class="headerlink" title="基础用法"></a>基础用法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wrk -t12 -c400 -d30s http://127.0.0.1:8080/index.html</span><br></pre></td></tr></table></figure>
<p>这个命令代表起 <code>12</code> 个线程来保持 <code>400</code>个 http连接，持续<code>30</code>秒。<br>输出如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Running 30s <span class="built_in">test</span> @ http://127.0.0.1:8080/index.html</span><br><span class="line">  12 threads and 400 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   635.91us    0.89ms  12.92ms   93.69%</span><br><span class="line">    Req/Sec    56.20k     8.07k   62.00k    86.54%</span><br><span class="line">  22464657 requests <span class="keyword">in</span> 30.00s, 17.76GB <span class="built_in">read</span></span><br><span class="line">Requests/sec: 748868.53</span><br><span class="line">Transfer/sec:    606.33MB</span><br></pre></td></tr></table></figure>
<h2 id="参数解释"><a href="#参数解释" class="headerlink" title="参数解释"></a>参数解释</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">-c, --connections: 要保持的连接总数，每个线程要处理链接数 = 连接总数/线程数</span><br><span class="line"></span><br><span class="line">-d, --duration:    测试持续事件, 如 2s, 2m, 2h</span><br><span class="line"></span><br><span class="line">-t, --threads:     总线程数</span><br><span class="line"></span><br><span class="line">-s, --script:      lua脚本, 参考上面的链接</span><br><span class="line"></span><br><span class="line">-H, --header:      要追加的http header e.g. <span class="string">&quot;User-Agent: wrk&quot;</span></span><br><span class="line"></span><br><span class="line">    --latency:     统计详细的延迟</span><br><span class="line"></span><br><span class="line">    --timeout:     如果一个请求在该时间内没有返回，则记录一个超时</span><br></pre></td></tr></table></figure>
<h2 id="使用技巧"><a href="#使用技巧" class="headerlink" title="使用技巧"></a>使用技巧</h2><p>运行wrk的计算机必须具有足够数量的临时端口(Port)，并且关闭的端口应该快速回收。为了处理初始连接突发，服务器(listen(2))[<a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man2/listen.2.html]%E7%9A%84backlog%E5%BA%94%E8%AF%A5%E5%A4%A7%E4%BA%8E%E6%AD%A3%E5%9C%A8%E6%B5%8B%E8%AF%95%E7%9A%84%E5%B9%B6%E5%8F%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E6%95%B0%E9%87%8F%E3%80%82">http://man7.org/linux/man-pages/man2/listen.2.html]的backlog应该大于正在测试的并发连接的数量。</a><br>(*这里稍微解释一下, listen 指linux的系统函数, 它的第二个参数 backlog 指定了能够服务的客户端最大数量，如果超过这个数量的请求都会被拒绝掉。 *)<br>仅更改HTTP Mehod，Path，Header 或 Body 的不会对性能产生影响。每个请求的操作（特别是构建新的HTTP请求）以及使用response（）必然会减少可以生成的负载量。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/12/22/load-test/wrt-usage/README/" data-id="ckizkw7u5000fzolmf6zheuz1" data-title="Wrk" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">下一页 &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/12/22/prometheus/README/">Prometheus</a>
          </li>
        
          <li>
            <a href="/2020/12/22/pprof/README/">简单易懂的 pprof 手册</a>
          </li>
        
          <li>
            <a href="/2020/12/22/openresty-note/cpu-setting-in-cloudnative/README/">(no title)</a>
          </li>
        
          <li>
            <a href="/2020/12/22/openresty-note/README/">Openresty 笔记</a>
          </li>
        
          <li>
            <a href="/2020/12/22/net-analysis/README/">网络分析</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2020 Vinci Xu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>